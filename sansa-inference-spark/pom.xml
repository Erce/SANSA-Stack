<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>net.sansa-stack</groupId>
        <artifactId>sansa-inference-parent</artifactId>
        <version>0.1.0-SNAPSHOT</version>
    </parent>
    <artifactId>sansa-inference-spark</artifactId>
    <version>0.1.0-SNAPSHOT</version>

    <name>Inference API - Spark</name>
    <description>Apache Spark based inference layer for RDF and OWL</description>

    <properties>
        <spark.deps.scope>compile</spark.deps.scope>
    </properties>

    <dependencies>
        <dependency>
            <groupId>net.sansa-stack</groupId>
            <artifactId>sansa-inference-common</artifactId>
            <version>${project.parent.version}</version>
        </dependency>
        <dependency>
            <groupId>net.sansa-stack</groupId>
            <artifactId>sansa-inference-tests</artifactId>
            <version>${project.parent.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>

        <!-- RDF Layer -->
        <dependency>
            <groupId>${project.groupId}</groupId>
            <artifactId>sansa-rdf-spark-core</artifactId>
        </dependency>
        <dependency>
            <groupId>net.sansa-stack</groupId>
            <artifactId>sansa-rdf-partition-core</artifactId>
        </dependency>

        <!-- Query Layer -->
        <dependency>
            <groupId>net.sansa-stack</groupId>
            <artifactId>sansa-query-spark-sparqlify</artifactId>
        </dependency>
        <dependency>
            <groupId>org.aksw.jena-sparql-api</groupId>
            <artifactId>jena-sparql-api-server-standalone</artifactId>
        </dependency>

        <!-- Scala -->
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
        </dependency>

        <!-- Apache Spark Core -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.binary.version}</artifactId>
            <scope>${spark.deps.scope}</scope>
        </dependency>
        <!-- Apache Spark SQL -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.binary.version}</artifactId>
            <scope>${spark.deps.scope}</scope>
        </dependency>

        <!-- Shapeless lib -->
        <dependency>
            <groupId>com.chuusai</groupId>
            <artifactId>shapeless_${scala.binary.version}</artifactId>
        </dependency>

        <!-- Apache JENA 3.x-->
        <dependency>
            <groupId>org.apache.jena</groupId>
            <artifactId>jena-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.apache.jena</groupId>
            <artifactId>jena-arq</artifactId>
        </dependency>

        <!-- Graph API -->
        <dependency>
            <groupId>com.assembla.scala-incubator</groupId>
            <artifactId>graph-core_${scala.binary.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>com.assembla.scala-incubator</groupId>
            <artifactId>graph-dot_${scala.binary.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>org.jgrapht</groupId>
            <artifactId>jgrapht-core</artifactId>
        </dependency>
        <dependency>
            <groupId>org.jgrapht</groupId>
            <artifactId>jgrapht-ext</artifactId>
        </dependency>
        <dependency>
            <groupId>org.gephi</groupId>
            <artifactId>gephi-toolkit</artifactId>
        </dependency>

        <!-- Test -->
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.binary.version}</artifactId>
        </dependency>
        <dependency>
            <groupId>com.holdenkarau</groupId>
            <artifactId>spark-testing-base_${scala.binary.version}</artifactId>
            <version>2.0.0_0.4.4</version>
            <scope>test</scope>
        </dependency>

        <!-- Logging -->
        <dependency>
            <groupId>com.typesafe.scala-logging</groupId>
            <artifactId>scala-logging_${scala.binary.version}</artifactId>
        </dependency>

        <!-- Scopt -->
        <dependency>
            <groupId>com.github.scopt</groupId>
            <artifactId>scopt_${scala.binary.version}</artifactId>
        </dependency>

    </dependencies>

    <build>
        <sourceDirectory>src/main/scala</sourceDirectory>
        <testSourceDirectory>src/test/scala</testSourceDirectory>
        <plugins>
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
            </plugin>

            <plugin>
                <artifactId>maven-compiler-plugin</artifactId>
            </plugin>

            <!-- disable surefire -->
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>2.19.1</version>
                <configuration>
                    <useFile>false</useFile>
                    <disableXmlReport>true</disableXmlReport>
                    <!--<forkCount>1</forkCount>-->
                    <!--<reuseForks>false</reuseForks>-->

                    <!-- If you have classpath issue like NoDefClassError,... -->
                    <!-- useManifestOnlyJar>false</useManifestOnlyJar -->
                    <threadCountSuites>4</threadCountSuites>
                    <includes>
                        <include>**/*Test.*</include>
                        <include>**/*Suite.*</include>
                    </includes>
                    <skipTests>true</skipTests>
                </configuration>
            </plugin>

            <!-- enable scalatest -->
            <plugin>
              <groupId>org.scalatest</groupId>
              <artifactId>scalatest-maven-plugin</artifactId>
              <configuration>
                <reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
                <junitxml>.</junitxml>
                <filereports>WDF TestSuite.txt</filereports>
              </configuration>
              <executions>
                <execution>
                  <id>test</id>
                  <goals>
                    <goal>test</goal>
                  </goals>
                </execution>
              </executions>
            </plugin>
        </plugins>
    </build>

    <profiles>
        <profile>
            <id>dist</id>
            <activation>
                <property>
                    <name>dist</name>
                </property>
            </activation>
            <!-- This profile uses the assembly plugin to create a special "dist" package for BigTop
                 that contains Spark but not the Hadoop JARs it depends on. -->
            <build>
                <plugins>
                    <!--<plugin>-->
                        <!--<groupId>org.apache.maven.plugins</groupId>-->
                        <!--<artifactId>maven-assembly-plugin</artifactId>-->
                        <!--<version>3.0.0</version>-->
                        <!--<executions>-->
                            <!--<execution>-->
                                <!--<id>dist</id>-->
                                <!--<phase>package</phase>-->
                                <!--<goals>-->
                                    <!--<goal>single</goal>-->
                                <!--</goals>-->
                                <!--<configuration>-->
                                    <!--&lt;!&ndash;<descriptorRefs>&ndash;&gt;-->
                                        <!--&lt;!&ndash;<descriptorRef>jar-with-dependencies</descriptorRef>&ndash;&gt;-->
                                    <!--&lt;!&ndash;</descriptorRefs>&ndash;&gt;-->
                                    <!--<descriptors>-->
                                        <!--<descriptor>src/main/assembly/assembly.xml</descriptor>-->
                                    <!--</descriptors>-->
                                <!--</configuration>-->
                            <!--</execution>-->
                        <!--</executions>-->
                    <!--</plugin>-->
                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-shade-plugin</artifactId>
                        <version>2.4.3</version>
                        <executions>
                            <execution>
                                <phase>package</phase>
                                <goals>
                                    <goal>shade</goal>
                                </goals>
                                <configuration>
                                    <artifactSet>
                                        <excludes>
                                            <exclude>org.apache.spark:spark-core_${scala.binary.version}</exclude>
                                            <exclude>org.apache.spark:spark-sql_${scala.binary.version}</exclude>
                                            <exclude>org.apache.spark:spark-graphx_${scala.binary.version}</exclude>
                                            <exclude>org.eclipse.jetty:jetty-server</exclude>
                                            <exclude>org.eclipse.jetty:jetty-continuation</exclude>
                                            <exclude>org.eclipse.jetty:jetty-http</exclude>
                                            <exclude>org.eclipse.jetty:jetty-io</exclude>
                                            <exclude>org.eclipse.jetty:jetty-util</exclude>
                                            <exclude>org.eclipse.jetty:jetty-security</exclude>
                                            <exclude>org.eclipse.jetty:jetty-servlet</exclude>
                                            <exclude>org.eclipse.jetty:*</exclude>
                                            <exclude>org.eclipse.*:*</exclude>
                                            <exclude>org.glassfish.*:*</exclude>
                                            <exclude>org.netbeans.api:*</exclude>
                                            <exclude>org.scala-lang:scala-library</exclude>
                                            <exclude>org.scala-lang:scala-compiler</exclude>
                                            <exclude>org.scala-lang:scala-reflect</exclude>
                                        </excludes>

                                    </artifactSet>
                                    <filters>
                                        <filter>
                                            <artifact>*:*</artifact>
                                            <excludes>
                                                <!-- Avoid a Spark error: Invalid signature file digest for Manifest main attributes-->
                                                <exclude>META-INF/*.SF</exclude>
                                                <exclude>META-INF/*.DSA</exclude>
                                                <exclude>META-INF/*.RSA</exclude>
                                            </excludes>
                                        </filter>
                                    </filters>
                                    <finalName>uber-${project.artifactId}-${project.version}</finalName>
                                    <transformers>
                                        <transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">
                                            <mainClass>net.sansa_stack.inference.spark.RDFGraphMaterializer</mainClass>
                                        </transformer>
                                    </transformers>
                                    <createDependencyReducedPom>false</createDependencyReducedPom>
                                </configuration>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>

        <!-- Profile that disables inclusion of Spark dependencies. -->
        <profile>
            <id>spark-provided</id>
            <activation>
                <property>
                    <name>dist</name>
                </property>
            </activation>
            <properties>
                <spark.deps.scope>provided</spark.deps.scope>
            </properties>
        </profile>

    </profiles>
</project>
